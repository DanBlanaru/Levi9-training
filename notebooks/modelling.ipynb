{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import DMatrix, cv\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = \"raw_data//\"\n",
    "processed_data_folder = \"processed_data//\"\n",
    "models_folder = \"models//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_train_onehot = pd.read_csv(processed_data_folder + \"standardized_train_onehot.csv\")\n",
    "standardized_test_onehot = pd.read_csv(processed_data_folder + \"standardized_train_onehot.csv\")\n",
    "\n",
    "standardized_train_ordinal = pd.read_csv(processed_data_folder + \"standardized_train_ordinal.csv\")\n",
    "standardized_test_ordinal = pd.read_csv(processed_data_folder + \"standardized_train_ordinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True, # Annotate the boxes \n",
    "                     cbar=False,\n",
    "                     fmt = 'g')\n",
    "\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "Since we have data that is mostly categorical, we can draw some conclusions:\n",
    "1. A neural network/perceptron/logistic regression probably will not perform well\n",
    "2. We dont have text data so a weighted Bayes is not preferred\n",
    "\n",
    "A good aspect of this dataset is it's medium sized, meaning:\n",
    "1. We can brute force(Grid Search) a lot of algortihms to see what si best, then refine the search for some\n",
    "2. We can make try both encodings, and see if the best performing algorithms prefer one or the other.\n",
    "<br>\n",
    "We will first make use of just the F1 score for quick and dirty filtering of algorithms. Given one single metric, we can quicly eliminate the low performers. \n",
    "<br>\n",
    "After we eliminate the low performers, we can compare the metrics on the better ones and even retrain using finer Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make functions out of each model training, so they can be adapted to different data preprocessings and be iterated upon.\n",
    "<br>\n",
    "All the models have a default grid, but can be fed different search grids as a function parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search_model(X,Y,model, grid, n_iter,n_jobs = 6):\n",
    "    \"\"\"Perform randomized parameter search on the model according to the grid.\n",
    "    This function requires the full dataset because it makes use of cross-validation\"\"\"\n",
    "    rs_classif = RandomizedSearchCV(estimator = model, param_distributions= grid,\n",
    "                                    n_iter = n_iter, cv = 5, verbose = 1,n_jobs = n_jobs)\n",
    "    rs_classif.fit(X,Y)\n",
    "    return rs_classif\n",
    "\n",
    "def grid_search_model(X,Y,model, grid,n_jobs = 6):\n",
    "    gs_classif = GridSearchCV(estimator = model, param_grid = grid,\n",
    "                              cv =5, verbose = 1, n_jobs = n_jobs)\n",
    "    gs_classif.fit(X,Y)\n",
    "    return gs_classif\n",
    "\n",
    "def eval_on_test(model,X,Y,method = f1_score):\n",
    "    Y_pred = model.predict(X)\n",
    "    value = method(Y,Y_pred)\n",
    "    print(value)\n",
    "    return value\n",
    "\n",
    "def full_metrics(model,x,y):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "    \"\"\"\n",
    "    y_true = y\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 4),\n",
    "                   \"precision\": round(precision, 4), \n",
    "                   \"recall\": round(recall, 4),\n",
    "                   \"f1\": round(f1, 4)}\n",
    "    print(f\"Acc: {accuracy * 100:.4f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 score: {f1:.4f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train, X_test, Y_train, Y_test, grid = None):\n",
    "    if grid is None:\n",
    "        grid_rf = {\"n_estimators\": [,40,50,100],\n",
    "                \"max_depth\": [None, 5, 10, 20],\n",
    "                \"max_features\": [\"auto\", \"sqrt\"],\n",
    "                \"min_samples_split\": [2, 4, 6],\n",
    "                \"min_samples_leaf\": [1, 2, 4]}\n",
    "    else:\n",
    "        grid_rf = grid\n",
    "#     parameter_grid = {\n",
    "#                  'max_depth' : [4, 6, 8],\n",
    "#                  'n_estimators': [50, 10],\n",
    "#                  'max_features': ['sqrt', 'auto', 'log2'],\n",
    "#                  'min_samples_split': [2, 3, 10],\n",
    "#                  'min_samples_leaf': [1, 3, 10],\n",
    "#                  'bootstrap': [True, False],\n",
    "#                  }\n",
    "    rf = grid_search_model(X_train,Y_train,RandomForestClassifier(),grid_rf)\n",
    "    f1 = (eval_on_test(rf,X_train,Y_train), \n",
    "          eval_on_test(rf, X_test, Y_test))\n",
    "    return rf,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svc(X_train, X_test, Y_train, Y_test, grid = None):\n",
    "    if grid is None:\n",
    "        grid_svc = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [10, 100, 1000, 2000]},\n",
    "                {'kernel': ['linear'], 'C': [10, 100, 1000, 2000]}]\n",
    "    else:\n",
    "        grid_svc = grid\n",
    "    svc = randomized_search_model(X_train,Y_train,SVC(),grid_svc,20)\n",
    "    f1 = (eval_on_test(svc,X_train,Y_train), \n",
    "          eval_on_test(svc, X_test, Y_test))\n",
    "    return svc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(X_train, X_test, Y_train, Y_test, grid = None):\n",
    "    if grid is None:\n",
    "        grid_knn = [{'n_neighbors': [3,5,7,11], 'weights':['uniform','distance'], 'metric': ['euclidean','manhattan']}]\n",
    "    else:\n",
    "        grid_knn = grid\n",
    "    knn = grid_search_model(X_train, Y_train, KNeighborsClassifier(),grid_knn)\n",
    "    f1 = (eval_on_test(knn,X_train,Y_train), \n",
    "          eval_on_test(knn, X_test, Y_test))\n",
    "    return knn,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adaboost(X_train, X_test, Y_train, Y_test, grid = None):\n",
    "#     grid_adaboost = {\n",
    "#      'n_estimators': [50,75, 100],\n",
    "#      'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    "#      'loss' : ['linear', 'square', 'exponential']\n",
    "#      }\n",
    "    if grid is None:\n",
    "        grid_adaboost = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                         \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "                         \"n_estimators\": [50,75,100,125]}\n",
    "    else:\n",
    "        grid_adaboost = grid\n",
    "    # ab = AdaBoostClassifier().fit(X_train,Y_train)\n",
    "    DTC = DecisionTreeClassifier(max_features = \"auto\",max_depth = 6)\n",
    "\n",
    "    adaboost = grid_search_model(X_train,Y_train, AdaBoostClassifier(base_estimator= DTC), grid_adaboost)\n",
    "\n",
    "    f1 = (eval_on_test(adaboost,X_train,Y_train), \n",
    "          eval_on_test(adaboost, X_test, Y_test))\n",
    "    return adaboost,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_gp(X_train, X_test, Y_train, Y_test):\n",
    "#     grid_gp = {'kernel':[RBF(1.0), 0.5* RBF(1.0), 0.33* RBF(1.0), 0.1 * RBF(1.0), RBF(0.5)],\n",
    "#                  'n_restarts_optimizer' : [0,1,2,3]}\n",
    "#     gp = grid_search_model(X_train, Y_train, GaussianProcessClassifier(RBF(1.0)), grid_gp, 5)\n",
    "\n",
    "#     eval_on_test(gp,X_train,Y_train)\n",
    "#     eval_on_test(gp,X_test,Y_test)\n",
    "#     return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, X_test, Y_train, Y_test, grid = None, early_stopping_rounds=50):\n",
    "    \n",
    "    if grid is None:\n",
    "        grid_xg ={\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'max_depth': [3, 4, 5]\n",
    "            }\n",
    "    else:\n",
    "        grid_xg = grid\n",
    "    xgb = XGBClassifier(\n",
    "     learning_rate =0.1,\n",
    "     n_estimators=1000,\n",
    "     max_depth=5,\n",
    "     min_child_weight=1,\n",
    "     gamma=0,\n",
    "     subsample=0.8,\n",
    "     colsample_bytree=0.8,\n",
    "     objective= 'binary:logistic',\n",
    "     nthread=4,\n",
    "     scale_pos_weight=1)\n",
    "    \n",
    "    \n",
    "#     gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "#      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#      objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "#      param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    xgb_param = xgb.get_xgb_params()\n",
    "    xgtrain = DMatrix(X_train, label=Y_train)\n",
    "    cvresult = cv(xgb_param, xgtrain, num_boost_round=xgb.get_params()['n_estimators'], nfold=5,\n",
    "        metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "    xgb.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    xgb.fit(X_train, Y_train)\n",
    "\n",
    "    f1 = (eval_on_test(xgb,X_train,Y_train), \n",
    "          eval_on_test(xgb, X_test, Y_test))\n",
    "    return xgb,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_all(X_train, X_test, Y_train, Y_test):\n",
    "    sep = '-'*80\n",
    "    print(sep)\n",
    "    print(\"Random Forest\",flush=True)\n",
    "    rf, rff1 = train_rf(X_train, X_test, Y_train, Y_test)\n",
    "    print(sep)\n",
    "    print(\"Support Vector Classifier\",flush=True)\n",
    "    svc, svcf1 = train_svc(X_train, X_test, Y_train, Y_test)\n",
    "    print(sep)\n",
    "    print(\"K Nearest Neighbors\",flush=True)\n",
    "    knn, knnf1 = train_knn(X_train, X_test, Y_train, Y_test)\n",
    "    print(sep)\n",
    "    print(\"Adaboost\",flush=True)\n",
    "    adaboost,adaboostf1 = train_adaboost(X_train, X_test, Y_train, Y_test)\n",
    "#     print('-'*20)\n",
    "#     print(\"Gaussian Process\")\n",
    "#     gp = train_gp(X_train, X_test, Y_train, Y_test)\n",
    "    print(sep)\n",
    "    print(\"XGBoost Classifier\")\n",
    "    xgb,xgbf1 = train_xgb(X_train, X_test, Y_train, Y_test)\n",
    "    print(sep)\n",
    "    print(\"\")\n",
    "    return {'rf':(rf,rff1),'svc':(svc,svcf1),'knn':(knn,knnf1),'adaboost':(adaboost,adaboostf1),'xgb':(xgb,xgbf1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Random Forest\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=6)]: Done 416 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=6)]: Done 666 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=6)]: Done 1016 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=6)]: Done 1440 out of 1440 | elapsed:  1.0min finished\n",
      "E:\\Programe\\Anaconda3\\envs\\rltorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829827915869981\n",
      "0.7868852459016392\n",
      "--------------------\n",
      "Support Vector Classifier\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  60 out of  60 | elapsed:   31.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741935483870968\n",
      "0.8\n",
      "--------------------\n",
      "K Nearest Neighbors\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "0.7933579335793357\n",
      "0.8319999999999999\n",
      "--------------------\n",
      "Adaboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=6)]: Done  69 out of  80 | elapsed:    2.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9383177570093458\n",
      "0.7559055118110236\n",
      "--------------------\n",
      "XGBoost Classifier\n",
      "0.8073394495412843\n",
      "0.7619047619047619\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import split_train\n",
    "onehot_split = split_train(standardized_train_onehot,.2)\n",
    "models_onehot = train_all(*onehot_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Random Forest\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 364 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=6)]: Done 864 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=6)]: Done 1440 out of 1440 | elapsed:   31.6s finished\n",
      "E:\\Programe\\Anaconda3\\envs\\rltorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764478764478766\n",
      "0.8029197080291972\n",
      "--------------------\n",
      "Support Vector Classifier\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  60 out of  60 | elapsed:   36.8s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671232876712328\n",
      "0.7887323943661971\n",
      "--------------------\n",
      "K Nearest Neighbors\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "0.7976878612716762\n",
      "0.7659574468085105\n",
      "--------------------\n",
      "Adaboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795158286778398\n",
      "0.7153284671532847\n",
      "--------------------\n",
      "XGBoost Classifier\n",
      "0.8863198458574182\n",
      "0.7611940298507464\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordinal_split = split_train(standardized_train_ordinal,.2)\n",
    "models_ordinal = train_all(*ordinal_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative training approach\n",
    "Now that we have a raw sense of what each algorithms does with each encoding, we can move on to iterating the best.\n",
    "<br>\n",
    "We will choose two categories:\n",
    "1. The ones that overfit the training set, because that gives us the choice to regularize and decrease variance to improve performance\n",
    "2. The ones that do well out of the box,giving good performance on both the cross-validation tests and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(models,\"..//models//onehot_models_it1.pkl\")\n",
    "# joblib.dump(models_ordinal,\"..//models//ordinal_models_it1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot_models = joblib.load(\"..//models//onehot_models_it1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
